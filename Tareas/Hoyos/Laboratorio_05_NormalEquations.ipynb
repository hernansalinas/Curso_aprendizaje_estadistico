{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNutRFwDsT-B"
   },
   "source": [
    "# Normal equation\n",
    "Se puede encontrar una solucion exacta para theta sin necesidad de emplear el gradiente descente de la sesiones pasadas, para ellos se puede encontrar el valor minimo de theta y a partir de alli determinar el valor de theta que minimiza J. \n",
    "\n",
    "Los pasos para esta minimizacion se dejan como tarea, y pueden ser calculados según lo siguiente:\n",
    "\n",
    "Si J es la funcion de coste dada por:\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\theta_1,\\theta_2,\\theta_3, ...,\\theta_n )=\\frac{1}{2m} \\sum_{i = 1}^m (\\Theta^{T} X - \\hat{y}^{(i)})^2\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Demostrar que:\n",
    "\n",
    "- $J(\\theta_1,\\theta_2,\\theta_3, ...,\\theta_n ) = \\frac{1}{2m} (\\Theta ^ T X - y)^T (\\Theta ^ T X - y)$\n",
    "\n",
    "- $ \\nabla _{\\theta} J = \\frac{1}{m}( (X^T X) \\Theta - X^T y)$\n",
    "\n",
    "\n",
    "Para encontrar el valor minimo de \\theta,  $\\nabla _{\\theta} J = 0$, \n",
    "\n",
    "- $\\Theta = (X^T X)^{-1} X^T y$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Para la demostracion anterior emplee las siguientes propiedades:\n",
    "\n",
    "- $z^T z= \\sum_i z_i^2$\n",
    "- $a^T b = b^Ta$\n",
    "- $\\nabla _x b^T x = b$\n",
    "- $\\nabla _x  x^T A x = 2Ax$\n",
    "\n",
    "donde a, b, x son matrices, $\\nabla_x$ es la derivada respecto al vector x, y A es una matriz simétrica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZyetWq9sWxq"
   },
   "source": [
    "1. Para los datos del laboratorio anterior aplicar la ecuacion normal.\n",
    "2. Tomar el dataset de las casas de Boston y construir un modelo de regresión mutivariada.\n",
    "\n",
    "```\n",
    "# Tomar los datos de las casas de boston y hacer una regresion lineal tomando \n",
    "# el average number of rooms per dwelling.\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n",
    "\n",
    "df = pd.DataFrame({\"mean_\":target, \"rm\":data[:,5]})\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtlcDPkgsw0t"
   },
   "source": [
    "# Intepretación Probabilistica. \n",
    "\n",
    "Supongamos que tenemos una caracteristica $x_i$ con m valores de entrenamiento, si asumimos que cada valor $y_i$ presenta una dispersión gaussiana $\\epsilon_i$, cada $y_i$ podrá tener el siguiente valor:\n",
    "\n",
    "$y^{i} = \\Theta^T X^{(i)} + \\epsilon_i$\n",
    "\n",
    "Asumiendo ademas que el ruido gaussiando es aleatorio y esta distribuido de forma identica, con media cero y varianza $\\sigma$, tenemos que la probabilidad de que la cantidad y tenga  dispersion $\\epsilon_i$ es:\n",
    "\\begin{equation}\n",
    "p(\\epsilon^{(i)})=\\frac{1}{\\sqrt{2\\pi\\sigma}} e^{-\\frac{ \\left( \\epsilon^{(i)}\\right)^2 }{2\\sigma ^2}}\n",
    "\\end{equation}\n",
    "\n",
    "Escribiendo, lo anterior en terminos de la probabilidad de obtener un valor de $y^{i}$ dado un $x^{i}$ parametrizado por $\\theta$ obtenemos que:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "p_i(y^{i}|x^{i};\\theta)=\\frac{1}{\\sqrt{2\\pi\\sigma}} e^{-\\frac{ \\left( y_i - \\Theta^T X^{(i)} \\right)^2 }{2\\sigma ^2}}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "Si ausmimos independencia estadística de cada $\\epsilon^{(i)}$, la probabilidad $L(\\theta)$ asociada a toda la distribución de puntos viene dada por:\n",
    "\n",
    "\\begin{equation}\n",
    "\\cal{L}(\\theta) = p(\\vec{y}|X;\\theta)=\\prod_{i=1}^{n} p_i(y^{i}|x^{i};\\theta)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\cal{L}(\\theta) =\\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma}} e^{-\\frac{ \\left( y_i - \\Theta^T X^{(i)} \\right)^2 }{2\\sigma ^2}}\n",
    "\\end{equation}\n",
    "\n",
    "para tener la mejor estimación posible de los valores que se deben elegir de  $\\theta$, se escogeran los parámetros que generan la mayor probabilidad de ocurrencia según las observaciones, es decir, aquellos valores para el cual $L(\\theta)$ es máximo, si aplicamos el logaritmo natural antes de máximar tenemos que:\n",
    "\n",
    "\\begin{equation}\n",
    "\\ln \\cal{L}(\\theta) = \\cal{l}(\\theta) = \\ln \\left[\\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma}} e^{-\\frac{ \\left( y_i - \\Theta^T X^{(i)} \\right)^2 }{2\\sigma ^2}} \\right]\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Después de un par de pasos se puede encontrar que:\n",
    "\n",
    "\\begin{equation}\n",
    "\\cal{l}(\\theta) = n\\ln \\frac{1}{\\sqrt{2\\pi\\sigma}} - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (y^{i}-\\Theta^T X^{i})^2\n",
    "\\end{equation},\n",
    "\n",
    "maximar $\\cal{l(\\theta)}$ equivale a encontrar donde  $\\nabla_{\\theta} \\cal{l(\\theta)} = 0$. Lo anterior muestra por que la elección de minimos cuadrados puede ser una buena eleccción para el analisis de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.21909486 9.64078118 5.17623353]\n"
     ]
    }
   ],
   "source": [
    "def f(x1,x2):\n",
    "    y=2.1*x1-3.1*x2\n",
    "    return y\n",
    "x1=np.random.uniform(0,10,10)\n",
    "x2=np.random.uniform(0,10,10)\n",
    "y=f(x1,x2)\n",
    "\n",
    "X=np.zeros((3,10))\n",
    "Theta=np.random.uniform(0,10,3)\n",
    "Theta=np.ones(3)*Theta\n",
    "\n",
    "print(Theta)\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(len(x1)):\n",
    "        \n",
    "        \n",
    "        if(i==1):\n",
    "            X[i][j]=x1[j]\n",
    "        elif(i==2):\n",
    "            X[i][j]=x2[j]\n",
    "        elif(i==0):\n",
    "            X[i][j]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta_final=np.dot(np.linalg.inv(np.dot(X,X.T)),np.dot(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.97379915e-14,  2.10000000e+00, -3.10000000e+00])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n",
    "\n",
    "df = pd.DataFrame({\"mean_\":target, \"rm\":data[:,5]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_</th>\n",
       "      <th>rm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>6.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.6</td>\n",
       "      <td>6.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.7</td>\n",
       "      <td>7.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.4</td>\n",
       "      <td>6.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.2</td>\n",
       "      <td>7.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>22.4</td>\n",
       "      <td>6.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>20.6</td>\n",
       "      <td>6.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>23.9</td>\n",
       "      <td>6.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>11.9</td>\n",
       "      <td>6.030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_     rm\n",
       "0     24.0  6.575\n",
       "1     21.6  6.421\n",
       "2     34.7  7.185\n",
       "3     33.4  6.998\n",
       "4     36.2  7.147\n",
       "..     ...    ...\n",
       "501   22.4  6.593\n",
       "502   20.6  6.120\n",
       "503   23.9  6.976\n",
       "504   22.0  6.794\n",
       "505   11.9  6.030\n",
       "\n",
       "[506 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.zeros((3,len(df[\"mean_\"])))\n",
    "for i in range(3):\n",
    "    for j in range(len(df[\"mean_\"])):\n",
    "        \n",
    "        \n",
    "        if(i==1):\n",
    "            X[i][j]=df[\"mean_\"][j]\n",
    "        elif(i==2):\n",
    "            X[i][j]=df[\"rm\"][j]\n",
    "        elif(i==0):\n",
    "            X[i][j]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.   ,  1.   ,  1.   , ...,  1.   ,  1.   ,  1.   ],\n",
       "       [24.   , 21.6  , 34.7  , ..., 23.9  , 22.   , 11.9  ],\n",
       "       [ 6.575,  6.421,  7.185, ...,  6.976,  6.794,  6.03 ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'longitude'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-6087e1c1fcc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sesion_07_housing.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;31m# converting the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(chunk_size)\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mfloatconv\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'0x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'longitude'"
     ]
    }
   ],
   "source": [
    "np.loadtxt(\"Sesion_07_housing.csv\", delimiter=\",\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Laboratio05_NormalEquations.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
